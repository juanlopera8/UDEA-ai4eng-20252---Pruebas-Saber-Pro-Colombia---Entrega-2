{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "853a793ca55f49f7998a18582489d9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bdaedb2d5424d5bb3b91c9296924e6e",
              "IPY_MODEL_4fd89de898794ce5ab887fbf50ec5e60",
              "IPY_MODEL_92dfd0c7737d42e8b4920042c9d852d7"
            ],
            "layout": "IPY_MODEL_c189517186f3407ba6260cda2ad1886b"
          }
        },
        "6bdaedb2d5424d5bb3b91c9296924e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fea2fecb58dc477fbc6c7187cc46b53c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2497daff2aa444d3aac2566c59bfc705",
            "value": "Best‚Äátrial:‚Äá16.‚ÄáBest‚Äávalue:‚Äá-0.441372:‚Äá100%"
          }
        },
        "4fd89de898794ce5ab887fbf50ec5e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13c2753e7afa47398acd84e0060c6876",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7a269ccb3614ba0b4f96d3da7d7a3cc",
            "value": 20
          }
        },
        "92dfd0c7737d42e8b4920042c9d852d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7147e27a41246aba5c58588765a9890",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_57a4590338d14efc9c6dc251f0459a72",
            "value": "‚Äá20/20‚Äá[2:41:58&lt;00:00,‚Äá621.40s/it]"
          }
        },
        "c189517186f3407ba6260cda2ad1886b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea2fecb58dc477fbc6c7187cc46b53c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2497daff2aa444d3aac2566c59bfc705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13c2753e7afa47398acd84e0060c6876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a269ccb3614ba0b4f96d3da7d7a3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7147e27a41246aba5c58588765a9890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a4590338d14efc9c6dc251f0459a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "853a793ca55f49f7998a18582489d9d9",
            "6bdaedb2d5424d5bb3b91c9296924e6e",
            "4fd89de898794ce5ab887fbf50ec5e60",
            "92dfd0c7737d42e8b4920042c9d852d7",
            "c189517186f3407ba6260cda2ad1886b",
            "fea2fecb58dc477fbc6c7187cc46b53c",
            "2497daff2aa444d3aac2566c59bfc705",
            "13c2753e7afa47398acd84e0060c6876",
            "e7a269ccb3614ba0b4f96d3da7d7a3cc",
            "c7147e27a41246aba5c58588765a9890",
            "57a4590338d14efc9c6dc251f0459a72"
          ]
        },
        "id": "cYhz-uEwvO6l",
        "outputId": "cc2d7295-486a-4520-c0a1-c2768250b201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/404.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m399.4/404.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hüìå Sube train.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85778765-5c6b-4326-895a-97e05d66c7a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85778765-5c6b-4326-895a-97e05d66c7a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.csv to train.csv\n",
            "üìå Sube test.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-34d55071-1346-4c09-91e0-80204cba0abd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-34d55071-1346-4c09-91e0-80204cba0abd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.csv to test.csv\n",
            "üìå Sube submission_example.csv (o submission_example.csv)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e14bde1-2398-4713-8d5e-3f5c1620a79e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6e14bde1-2398-4713-8d5e-3f5c1620a79e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving submission_example.csv to submission_example.csv\n",
            "Shapes -> train: (692500, 21), test: (296786, 20), sample: (296786, 2)\n",
            "\n",
            "-- EDA R√°pido --\n",
            "Nulos por columna (top 20):\n",
            "F_TIENEAUTOMOVIL               43623\n",
            "F_TIENELAVADORA                39773\n",
            "F_TIENECOMPUTADOR              38103\n",
            "F_ESTRATOVIVIENDA              32137\n",
            "E_HORASSEMANATRABAJA           30857\n",
            "F_TIENEINTERNET.1              26629\n",
            "F_TIENEINTERNET                26629\n",
            "F_EDUCACIONMADRE               23664\n",
            "F_EDUCACIONPADRE               23178\n",
            "E_PAGOMATRICULAPROPIO           6498\n",
            "E_VALORMATRICULAUNIVERSIDAD     6287\n",
            "PERIODO_ACADEMICO                  0\n",
            "ID                                 0\n",
            "E_PRGM_DEPARTAMENTO                0\n",
            "E_PRGM_ACADEMICO                   0\n",
            "E_PRIVADO_LIBERTAD                 0\n",
            "RENDIMIENTO_GLOBAL                 0\n",
            "INDICADOR_1                        0\n",
            "INDICADOR_2                        0\n",
            "INDICADOR_3                        0\n",
            "dtype: int64\n",
            "\n",
            "Distribuci√≥n target:\n",
            "RENDIMIENTO_GLOBAL\n",
            "alto          175619\n",
            "bajo          172987\n",
            "medio-bajo    172275\n",
            "medio-alto    171619\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Primeras columnas: ['ID', 'PERIODO_ACADEMICO', 'E_PRGM_ACADEMICO', 'E_PRGM_DEPARTAMENTO', 'E_VALORMATRICULAUNIVERSIDAD', 'E_HORASSEMANATRABAJA', 'F_ESTRATOVIVIENDA', 'F_TIENEINTERNET', 'F_EDUCACIONPADRE', 'F_TIENELAVADORA', 'F_TIENEAUTOMOVIL', 'E_PRIVADO_LIBERTAD', 'E_PAGOMATRICULAPROPIO', 'F_TIENECOMPUTADOR', 'F_TIENEINTERNET.1', 'F_EDUCACIONMADRE', 'RENDIMIENTO_GLOBAL', 'INDICADOR_1', 'INDICADOR_2', 'INDICADOR_3', 'INDICADOR_4']\n",
            "\n",
            "Mapeo target (label -> c√≥digo): {'alto': 0, 'bajo': 1, 'medio-alto': 2, 'medio-bajo': 3}\n",
            "ID column detected: ID\n",
            "Total filas combinadas (train+test): (989286, 20)\n",
            "Num cols: 6, Cat cols: 14\n",
            "Target-encoding columns (high-cardinality): ['E_PRGM_ACADEMICO', 'E_PRGM_DEPARTAMENTO']\n",
            "Low-cardinality (factorize): ['E_VALORMATRICULAUNIVERSIDAD', 'E_HORASSEMANATRABAJA', 'F_ESTRATOVIVIENDA', 'F_TIENEINTERNET', 'F_EDUCACIONPADRE', 'F_TIENELAVADORA', 'F_TIENEAUTOMOVIL', 'E_PRIVADO_LIBERTAD', 'E_PAGOMATRICULAPROPIO', 'F_TIENECOMPUTADOR', 'F_TIENEINTERNET.1', 'F_EDUCACIONMADRE']\n",
            "\n",
            "Aplicando target-encoding CV-based a columnas con alta cardinalidad...\n",
            "TE: E_PRGM_ACADEMICO\n",
            "TE: E_PRGM_DEPARTAMENTO\n",
            "X_proc shape: (692500, 24)  test_proc shape: (296786, 24)\n",
            "\n",
            "==> Ejecutando Optuna para LightGBM (puede tardar)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-28 00:09:49,942] A new study created in memory with name: no-name-33910d7c-c374-48ab-804e-9d5122e56192\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "853a793ca55f49f7998a18582489d9d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[431]\tvalid_0's multi_logloss: 1.19205\n",
            "[I 2025-11-28 00:15:16,398] Trial 0 finished with value: -0.43812274368231047 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 192, 'min_child_samples': 75, 'feature_fraction': 0.759195090518222, 'bagging_fraction': 0.4936111842654619, 'bagging_freq': 1, 'lambda_l1': 0.2904180608409973, 'lambda_l2': 4.330880728874676}. Best is trial 0 with value: -0.43812274368231047.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[277]\tvalid_0's multi_logloss: 1.19146\n",
            "[I 2025-11-28 00:18:31,565] Trial 1 finished with value: -0.4376823104693141 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 148, 'min_child_samples': 6, 'feature_fraction': 0.9819459112971965, 'bagging_fraction': 0.899465584480253, 'bagging_freq': 2, 'lambda_l1': 0.9091248360355031, 'lambda_l2': 0.9170225492671691}. Best is trial 0 with value: -0.43812274368231047.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[906]\tvalid_0's multi_logloss: 1.18888\n",
            "[I 2025-11-28 00:26:13,780] Trial 2 finished with value: -0.4407942238267148 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 114, 'min_child_samples': 46, 'feature_fraction': 0.5747374841188252, 'bagging_fraction': 0.7671117368334277, 'bagging_freq': 1, 'lambda_l1': 1.4607232426760908, 'lambda_l2': 1.8318092164684585}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[409]\tvalid_0's multi_logloss: 1.18938\n",
            "[I 2025-11-28 00:30:22,090] Trial 3 finished with value: -0.44035379061371843 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 162, 'min_child_samples': 24, 'feature_fraction': 0.708540663048167, 'bagging_fraction': 0.7554487413172255, 'bagging_freq': 0, 'lambda_l1': 3.0377242595071916, 'lambda_l2': 0.8526206184364576}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's multi_logloss: 1.19113\n",
            "[I 2025-11-28 00:43:42,929] Trial 4 finished with value: -0.43849097472924187 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 191, 'min_child_samples': 97, 'feature_fraction': 0.8850384088698766, 'bagging_fraction': 0.5827682615040224, 'bagging_freq': 1, 'lambda_l1': 3.4211651325607844, 'lambda_l2': 2.2007624686980067}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's multi_logloss: 1.19279\n",
            "[I 2025-11-28 00:53:36,743] Trial 5 finished with value: -0.4380216606498195 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 109, 'min_child_samples': 8, 'feature_fraction': 0.9455922412472693, 'bagging_fraction': 0.5552679889600102, 'bagging_freq': 7, 'lambda_l1': 1.5585553804470549, 'lambda_l2': 2.600340105889054}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[797]\tvalid_0's multi_logloss: 1.19071\n",
            "[I 2025-11-28 00:59:46,827] Trial 6 finished with value: -0.43897472924187725 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 53, 'min_child_samples': 98, 'feature_fraction': 0.8650796940166687, 'bagging_fraction': 0.9636993649385135, 'bagging_freq': 9, 'lambda_l1': 2.9894998940554256, 'lambda_l2': 4.609371175115584}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's multi_logloss: 1.19432\n",
            "[I 2025-11-28 01:08:50,832] Trial 7 finished with value: -0.4378916967509025 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 55, 'min_child_samples': 9, 'feature_fraction': 0.5951981984579586, 'bagging_fraction': 0.6332063738136893, 'bagging_freq': 2, 'lambda_l1': 4.143687545759647, 'lambda_l2': 1.7837666334679465}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[744]\tvalid_0's multi_logloss: 1.19333\n",
            "[I 2025-11-28 01:16:31,049] Trial 8 finished with value: -0.4369025270758123 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 118, 'min_child_samples': 18, 'feature_fraction': 0.8813181884524238, 'bagging_fraction': 0.44473038620786254, 'bagging_freq': 10, 'lambda_l1': 3.861223846483287, 'lambda_l2': 0.993578407670862}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's multi_logloss: 1.19068\n",
            "[I 2025-11-28 01:27:51,535] Trial 9 finished with value: -0.44020938628158846 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 167, 'min_child_samples': 72, 'feature_fraction': 0.8374043008245924, 'bagging_fraction': 0.8627622080115674, 'bagging_freq': 0, 'lambda_l1': 1.7923286427213632, 'lambda_l2': 0.5793452976256486}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[602]\tvalid_0's multi_logloss: 1.19313\n",
            "[I 2025-11-28 01:31:06,989] Trial 10 finished with value: -0.43694584837545125 and parameters: {'learning_rate': 0.13388899274129873, 'num_leaves': 21, 'min_child_samples': 40, 'feature_fraction': 0.4107771253688918, 'bagging_fraction': 0.7415875015913806, 'bagging_freq': 4, 'lambda_l1': 4.7988537297270994, 'lambda_l2': 3.3342913754128913}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[216]\tvalid_0's multi_logloss: 1.19109\n",
            "[I 2025-11-28 01:33:29,563] Trial 11 finished with value: -0.438173285198556 and parameters: {'learning_rate': 0.08725992629268442, 'num_leaves': 119, 'min_child_samples': 35, 'feature_fraction': 0.602002915545646, 'bagging_fraction': 0.751681502013535, 'bagging_freq': 4, 'lambda_l1': 2.3635700332897436, 'lambda_l2': 0.0971772915511796}. Best is trial 2 with value: -0.4407942238267148.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[984]\tvalid_0's multi_logloss: 1.18856\n",
            "[I 2025-11-28 01:41:28,699] Trial 12 finished with value: -0.4408519855595668 and parameters: {'learning_rate': 0.025399132942428935, 'num_leaves': 145, 'min_child_samples': 33, 'feature_fraction': 0.6305847364975914, 'bagging_fraction': 0.7918018960865281, 'bagging_freq': 0, 'lambda_l1': 2.343526094439211, 'lambda_l2': 1.4832794507650817}. Best is trial 12 with value: -0.4408519855595668.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[997]\tvalid_0's multi_logloss: 1.1892\n",
            "[I 2025-11-28 01:50:49,824] Trial 13 finished with value: -0.44088808664259926 and parameters: {'learning_rate': 0.021309267585889136, 'num_leaves': 92, 'min_child_samples': 54, 'feature_fraction': 0.552793958689146, 'bagging_fraction': 0.8750843231350037, 'bagging_freq': 3, 'lambda_l1': 2.039294159774773, 'lambda_l2': 1.625169040298948}. Best is trial 13 with value: -0.44088808664259926.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's multi_logloss: 1.18979\n",
            "[I 2025-11-28 01:59:36,625] Trial 14 finished with value: -0.4404043321299639 and parameters: {'learning_rate': 0.019602282595315667, 'num_leaves': 83, 'min_child_samples': 60, 'feature_fraction': 0.4671856701988867, 'bagging_fraction': 0.837900897719021, 'bagging_freq': 5, 'lambda_l1': 2.31057379200564, 'lambda_l2': 3.0099365931421698}. Best is trial 13 with value: -0.44088808664259926.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[935]\tvalid_0's multi_logloss: 1.18889\n",
            "[I 2025-11-28 02:07:30,362] Trial 15 finished with value: -0.4392490974729242 and parameters: {'learning_rate': 0.03450357886193584, 'num_leaves': 89, 'min_child_samples': 58, 'feature_fraction': 0.510114182418116, 'bagging_fraction': 0.9364883648743151, 'bagging_freq': 3, 'lambda_l1': 0.7931282444695864, 'lambda_l2': 1.588105343653274}. Best is trial 13 with value: -0.44088808664259926.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[999]\tvalid_0's multi_logloss: 1.18875\n",
            "[I 2025-11-28 02:18:43,554] Trial 16 finished with value: -0.44137184115523465 and parameters: {'learning_rate': 0.01849780984169769, 'num_leaves': 147, 'min_child_samples': 30, 'feature_fraction': 0.6606538700483214, 'bagging_fraction': 0.9980575775453012, 'bagging_freq': 6, 'lambda_l1': 2.166697996531939, 'lambda_l2': 1.3973599487384367}. Best is trial 16 with value: -0.44137184115523465.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[999]\tvalid_0's multi_logloss: 1.1908\n",
            "[I 2025-11-28 02:29:00,811] Trial 17 finished with value: -0.4399350180505415 and parameters: {'learning_rate': 0.017881881836987763, 'num_leaves': 80, 'min_child_samples': 68, 'feature_fraction': 0.6955366407233073, 'bagging_fraction': 0.997124142886729, 'bagging_freq': 7, 'lambda_l1': 1.9076355697541554, 'lambda_l2': 3.7162679157114447}. Best is trial 16 with value: -0.44137184115523465.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[995]\tvalid_0's multi_logloss: 1.18862\n",
            "[I 2025-11-28 02:40:25,176] Trial 18 finished with value: -0.44114079422382674 and parameters: {'learning_rate': 0.016469926387045718, 'num_leaves': 136, 'min_child_samples': 48, 'feature_fraction': 0.5212826506746773, 'bagging_fraction': 0.9117129958096847, 'bagging_freq': 7, 'lambda_l1': 2.868447337527959, 'lambda_l2': 2.43008992109701}. Best is trial 16 with value: -0.44137184115523465.\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's multi_logloss: 1.18973\n",
            "[I 2025-11-28 02:51:48,730] Trial 19 finished with value: -0.440115523465704 and parameters: {'learning_rate': 0.017027923819082278, 'num_leaves': 139, 'min_child_samples': 24, 'feature_fraction': 0.6759917253247112, 'bagging_fraction': 0.6734877459778417, 'bagging_freq': 7, 'lambda_l1': 2.9547729768337527, 'lambda_l2': 2.5887405394092937}. Best is trial 16 with value: -0.44137184115523465.\n",
            "Optuna best value (neg acc): -0.44137184115523465\n",
            "Optuna best params: {'learning_rate': 0.01849780984169769, 'num_leaves': 147, 'min_child_samples': 30, 'feature_fraction': 0.6606538700483214, 'bagging_fraction': 0.9980575775453012, 'bagging_freq': 6, 'lambda_l1': 2.166697996531939, 'lambda_l2': 1.3973599487384367}\n",
            "Best LGB params prepared.\n",
            "\n",
            "==> Haciendo RandomizedSearch para RandomForest (r√°pido)...\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# Notebook completo para Colab\n",
        "# - EDA b√°sico\n",
        "# - Preprocesamiento (imputaci√≥n, factorize)\n",
        "# - Target encoding CV-based para categ√≥ricas de alta cardinalidad\n",
        "# - StratifiedKFold CV + OOF\n",
        "# - Optuna HPO para LightGBM (opcional) + RandomizedSearch para RF\n",
        "# - Ensemble promediando probabilidades LGBM + RF\n",
        "# - Generaci√≥n y descarga de submission.csv\n",
        "# ===============================\n",
        "\n",
        "# 0) Instalar dependencias\n",
        "!pip install -q lightgbm scikit-learn pandas optuna\n",
        "\n",
        "# 1) Imports\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, time\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 2) Subir archivos\n",
        "print(\"üìå Sube train.csv\")\n",
        "_ = files.upload()\n",
        "print(\"üìå Sube test.csv\")\n",
        "_ = files.upload()\n",
        "print(\"üìå Sube submission_example.csv (o submission_example.csv)\")\n",
        "_ = files.upload()\n",
        "\n",
        "# 3) Cargar datos\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "# try different names for sample\n",
        "sample_name = None\n",
        "for candidate in [\"submission_example.csv\", \"sample_submission.csv\", \"submission_example\", \"sample_submission\"]:\n",
        "    if os.path.exists(candidate):\n",
        "        sample_name = candidate\n",
        "        break\n",
        "if sample_name is None:\n",
        "    # create a dummy sample from test if none provided\n",
        "    print(\"No encontr√© sample_submission en los nombres comunes; se crear√° uno temporal desde test.\")\n",
        "    sample = pd.DataFrame({ 'ID': test.iloc[:,0], 'RENDIMIENTO_GLOBAL': ['bajo']*len(test) })\n",
        "else:\n",
        "    sample = pd.read_csv(sample_name)\n",
        "\n",
        "print(f\"Shapes -> train: {train.shape}, test: {test.shape}, sample: {sample.shape}\")\n",
        "\n",
        "# 4) EDA r√°pido y checks\n",
        "print(\"\\n-- EDA R√°pido --\")\n",
        "print(\"Nulos por columna (top 20):\")\n",
        "print(train.isna().sum().sort_values(ascending=False).head(20))\n",
        "print(\"\\nDistribuci√≥n target:\")\n",
        "print(train[\"RENDIMIENTO_GLOBAL\"].value_counts())\n",
        "print(\"\\nPrimeras columnas:\", train.columns.tolist()[:30])\n",
        "\n",
        "# 5) Preparar target -> map to ints\n",
        "TARGET = \"RENDIMIENTO_GLOBAL\"\n",
        "if TARGET not in train.columns:\n",
        "    raise ValueError(f\"No encontr√© la columna target '{TARGET}' en train.csv\")\n",
        "\n",
        "# Mapear etiquetas a ints (asegurar orden reproducible con sorted unique)\n",
        "unique_targets = sorted(train[TARGET].astype(str).unique().tolist())\n",
        "class_mapping = {c:i for i,c in enumerate(unique_targets)}\n",
        "inverse_mapping = {i:c for c,i in class_mapping.items()}\n",
        "print(\"\\nMapeo target (label -> c√≥digo):\", class_mapping)\n",
        "\n",
        "train['target_num'] = train[TARGET].astype(str).map(class_mapping)\n",
        "\n",
        "# 6) Separar X y y\n",
        "X = train.drop(columns=[TARGET, 'target_num'])\n",
        "y = train['target_num']\n",
        "test_ids_candidates = [c for c in test.columns if c.lower() in ['id','ids','Id','ID']]\n",
        "if len(test_ids_candidates)==0:\n",
        "    # fallback: use first column as ID\n",
        "    id_col = test.columns[0]\n",
        "    print(f\"No encontr√© columna ID expl√≠cita en test; usar√© la primera columna '{id_col}' como ID.\")\n",
        "else:\n",
        "    id_col = test_ids_candidates[0]\n",
        "print(\"ID column detected:\", id_col)\n",
        "\n",
        "# 7) Unir train+test para transformar iguales\n",
        "all_data = pd.concat([X, test], axis=0, ignore_index=True)\n",
        "n_train = len(X)\n",
        "n_test = len(test)\n",
        "print(\"Total filas combinadas (train+test):\", all_data.shape)\n",
        "\n",
        "# 8) Detectar tipos y decisiones de encoding\n",
        "num_cols = all_data.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
        "cat_cols = all_data.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
        "print(f\"Num cols: {len(num_cols)}, Cat cols: {len(cat_cols)}\")\n",
        "\n",
        "# 9) Imputaci√≥n num√©rica (median) y conservar NaN flags opcional\n",
        "for c in num_cols:\n",
        "    if all_data[c].isna().any():\n",
        "        all_data[c + \"_na_flag\"] = all_data[c].isna().astype(int)\n",
        "        all_data[c] = all_data[c].fillna(all_data[c].median())\n",
        "\n",
        "# 10) Preparar categ√≥ricas: decide target-encoding para cardinalidad alta\n",
        "cardinality = all_data[cat_cols].nunique().sort_values(ascending=False)\n",
        "# Umbral para considerar target encoding\n",
        "TE_CARDINALITY = 20\n",
        "te_cols = [c for c in cat_cols if all_data[c].nunique() > TE_CARDINALITY]\n",
        "low_card_cols = [c for c in cat_cols if all_data[c].nunique() <= TE_CARDINALITY]\n",
        "print(\"Target-encoding columns (high-cardinality):\", te_cols)\n",
        "print(\"Low-cardinality (factorize):\", low_card_cols)\n",
        "\n",
        "# 11) Factorize low-cardinality categorical columns\n",
        "for c in low_card_cols:\n",
        "    all_data[c] = all_data[c].fillna(\"MISSING\").astype(str)\n",
        "    all_data[c] = all_data[c].factorize()[0]\n",
        "\n",
        "# 12) Target encoding (out-of-fold) for high-cardinality columns\n",
        "# We'll perform target-encoding using only TRAIN rows; for test use global means from train\n",
        "def target_encode_oof(train_df, full_df, col, target, n_splits=5, random_state=42):\n",
        "    \"\"\"\n",
        "    train_df: dataframe with only train rows (index aligned to 0..n_train-1)\n",
        "    full_df: concatenated all_data used for mapping (train+test)\n",
        "    col: column name in full_df to encode\n",
        "    target: Series with numeric labels for train\n",
        "    returns: encoded_train (np array length n_train), encoded_full_test_value (mapping for test)\n",
        "    \"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    oof = pd.Series(index=train_df.index, dtype=float)\n",
        "    for tr_idx, val_idx in skf.split(train_df, target):\n",
        "        means = pd.Series(train_df.iloc[tr_idx].groupby(col)[target.name].mean())\n",
        "        oof.iloc[val_idx] = train_df.iloc[val_idx][col].map(means)\n",
        "    # fill NA with global mean\n",
        "    global_mean = target.mean()\n",
        "    oof.fillna(global_mean, inplace=True)\n",
        "    # For test mapping: compute means on full train\n",
        "    train_means_full = train_df.groupby(col)[target.name].mean()\n",
        "    # map test values via full_df\n",
        "    test_values = full_df.iloc[n_train:][col].map(train_means_full).fillna(global_mean).values\n",
        "    return oof.values, test_values, train_means_full.to_dict()\n",
        "\n",
        "# Before target encoding we need the original string categories in the train slice\n",
        "# Ensure the columns exist as strings\n",
        "for c in te_cols:\n",
        "    all_data[c] = all_data[c].fillna(\"MISSING\").astype(str)\n",
        "\n",
        "# Prepare containers\n",
        "train_te_arrays = {}\n",
        "test_te_arrays = {}\n",
        "te_maps = {}\n",
        "\n",
        "if len(te_cols)>0:\n",
        "    print(\"\\nAplicando target-encoding CV-based a columnas con alta cardinalidad...\")\n",
        "    train_slice = all_data.iloc[:n_train].copy().reset_index(drop=True)\n",
        "    full_df = all_data.copy().reset_index(drop=True)\n",
        "    # attach target to train_slice for grouping\n",
        "    train_slice[TARGET] = train[TARGET].astype(str).values\n",
        "    # but for numeric means we need numeric target mapping\n",
        "    train_slice['target_num'] = y.values\n",
        "    for c in te_cols:\n",
        "        print(\"TE:\", c)\n",
        "        oof_vals, test_vals, mapping = target_encode_oof(train_slice, full_df, c, train_slice['target_num'], n_splits=5)\n",
        "        # create new columns in all_data: c+\"_te\"\n",
        "        all_data.loc[:n_train-1, c + \"_te\"] = oof_vals\n",
        "        all_data.loc[n_train:, c + \"_te\"] = test_vals\n",
        "        train_te_arrays[c] = oof_vals\n",
        "        test_te_arrays[c] = test_vals\n",
        "        te_maps[c] = mapping\n",
        "else:\n",
        "    print(\"No hay columnas de alta cardinalidad para target-encoding.\")\n",
        "\n",
        "# 13) After TE, drop original high-cardinality raw columns (optional) or keep both\n",
        "# We'll keep both but convert originals to factorized integers (to feed tree models)\n",
        "for c in te_cols:\n",
        "    all_data[c + \"_raw_factor\"] = all_data[c].factorize()[0]\n",
        "\n",
        "# 14) For any remaining object/category columns (should be none), factorize\n",
        "remaining_cat_cols = all_data.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
        "for c in remaining_cat_cols:\n",
        "    all_data[c] = all_data[c].astype(str).factorize()[0]\n",
        "\n",
        "# 15) Finalize X_proc and test_proc\n",
        "X_proc = all_data.iloc[:n_train].reset_index(drop=True)\n",
        "test_proc = all_data.iloc[n_train:].reset_index(drop=True)\n",
        "print(\"X_proc shape:\", X_proc.shape, \" test_proc shape:\", test_proc.shape)\n",
        "\n",
        "# 16) Parameters and settings for CV / models\n",
        "N_SPLITS = 5\n",
        "SEED = 42\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "# Containers for OOF probabilities and test predictions\n",
        "n_classes = len(class_mapping)\n",
        "oof_probs_lgb = np.zeros((n_train, n_classes))\n",
        "oof_probs_rf = np.zeros((n_train, n_classes))\n",
        "preds_test_lgb = np.zeros((n_test, n_classes))\n",
        "preds_test_rf = np.zeros((n_test, n_classes))\n",
        "\n",
        "# LightGBM params default (will be tuned)\n",
        "lgb_base_params = {\n",
        "    \"objective\": \"multiclass\",\n",
        "    \"num_class\": n_classes,\n",
        "    \"metric\": \"multi_logloss\",\n",
        "    \"verbosity\": -1,\n",
        "    \"seed\": SEED\n",
        "}\n",
        "\n",
        "# 17) Optuna HPO for LightGBM (per fold tuning optional) - we'll run once to get global best params\n",
        "USE_OPTUNA = True\n",
        "N_TRIALS_OPTUNA = 20  # reduce/increase per your time budget\n",
        "\n",
        "def optuna_lgb_objective(trial, Xtr, ytr, Xval, yval):\n",
        "    param = {\n",
        "        \"objective\": \"multiclass\",\n",
        "        \"num_class\": n_classes,\n",
        "        \"metric\": \"multi_logloss\",\n",
        "        \"verbosity\": -1,\n",
        "        \"seed\": SEED,\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 200),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
        "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
        "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
        "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 10),\n",
        "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 5.0),\n",
        "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 5.0),\n",
        "    }\n",
        "    dtrain = lgb.Dataset(Xtr, label=ytr)\n",
        "    dval = lgb.Dataset(Xval, label=yval, reference=dtrain)\n",
        "    bst = lgb.train(param, dtrain, num_boost_round=1000, valid_sets=[dval],\n",
        "                    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=0)])\n",
        "    preds = bst.predict(Xval, num_iteration=bst.best_iteration)\n",
        "    loss = -1.0 * (accuracy_score(yval, np.argmax(preds, axis=1)))  # we minimize negative accuracy\n",
        "    return loss\n",
        "\n",
        "best_lgb_params = None\n",
        "if USE_OPTUNA:\n",
        "    print(\"\\n==> Ejecutando Optuna para LightGBM (puede tardar)...\")\n",
        "    # We'll create a small train/val split from X_proc to tune quickly\n",
        "    X_tr_split, X_val_split, y_tr_split, y_val_split = train_test_split(X_proc, y, test_size=0.2, random_state=SEED, stratify=y)\n",
        "    def optuna_wrapper(trial):\n",
        "        return optuna_lgb_objective(trial, X_tr_split, y_tr_split, X_val_split, y_val_split)\n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=SEED))\n",
        "    study.optimize(optuna_wrapper, n_trials=N_TRIALS_OPTUNA, show_progress_bar=True)\n",
        "    print(\"Optuna best value (neg acc):\", study.best_value)\n",
        "    print(\"Optuna best params:\", study.best_params)\n",
        "    # Translate best_params into LightGBM params\n",
        "    best_lgb_params = {\n",
        "        \"objective\": \"multiclass\",\n",
        "        \"num_class\": n_classes,\n",
        "        \"metric\": \"multi_logloss\",\n",
        "        \"verbosity\": -1,\n",
        "        \"seed\": SEED,\n",
        "        **study.best_params\n",
        "    }\n",
        "    # ensure integer params if needed\n",
        "    best_lgb_params[\"num_leaves\"] = int(best_lgb_params.get(\"num_leaves\", 31))\n",
        "    print(\"Best LGB params prepared.\")\n",
        "else:\n",
        "    # Use defaults\n",
        "    best_lgb_params = {\n",
        "        **lgb_base_params,\n",
        "        \"learning_rate\": 0.05,\n",
        "        \"num_leaves\": 31\n",
        "    }\n",
        "\n",
        "# 18) RandomizedSearch for RandomForest (global)\n",
        "print(\"\\n==> Haciendo RandomizedSearch para RandomForest (r√°pido)...\")\n",
        "rf = RandomForestClassifier(random_state=SEED, n_jobs=-1)\n",
        "param_dist = {\n",
        "    \"n_estimators\": [100, 200, 400],\n",
        "    \"max_depth\": [5, 10, 20, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "N_ITER_RF = 20\n",
        "rs = RandomizedSearchCV(rf, param_dist, n_iter=N_ITER_RF, scoring=\"accuracy\", cv=3, random_state=SEED, n_jobs=-1, verbose=0)\n",
        "# fit on full processed X_proc to get best RF params (this uses factorized/TE features)\n",
        "rs.fit(X_proc, y)\n",
        "best_rf_params = rs.best_params_\n",
        "print(\"Best RF params:\", best_rf_params)\n",
        "\n",
        "# 19) Cross-validation loop: train LGBM and RF on each fold, collect OOF and test preds\n",
        "print(\"\\n==> Iniciando StratifiedKFold CV (Entrenando LGBM + RF en cada fold)...\")\n",
        "fold = 0\n",
        "for train_idx, val_idx in skf.split(X_proc, y):\n",
        "    fold += 1\n",
        "    print(f\"\\n--- Fold {fold} ---\")\n",
        "    X_tr, X_val = X_proc.iloc[train_idx], X_proc.iloc[val_idx]\n",
        "    y_tr, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    # LightGBM\n",
        "    dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
        "    dval = lgb.Dataset(X_val, label=y_val_fold, reference=dtrain)\n",
        "    lgb_params = best_lgb_params.copy()\n",
        "    # set reasonable n_estimators via num_boost_round\n",
        "    bst = lgb.train(lgb_params, dtrain, num_boost_round=1000, valid_sets=[dval],\n",
        "                    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=0)])\n",
        "    pred_val_lgb = bst.predict(X_val, num_iteration=bst.best_iteration)\n",
        "    pred_test_lgb = bst.predict(test_proc, num_iteration=bst.best_iteration)\n",
        "    oof_probs_lgb[val_idx] = pred_val_lgb\n",
        "    preds_test_lgb += pred_test_lgb / N_SPLITS\n",
        "\n",
        "    # RandomForest (fit on fold)\n",
        "    rf_model = RandomForestClassifier(**best_rf_params, random_state=SEED, n_jobs=-1)\n",
        "    rf_model.fit(X_tr, y_tr)\n",
        "    pred_val_rf_probs = rf_model.predict_proba(X_val)\n",
        "    pred_test_rf_probs = rf_model.predict_proba(test_proc)\n",
        "    # Note: RandomForest.predict_proba returns columns in order of rf_model.classes_\n",
        "    # We need to align classes order to 0..n_classes-1\n",
        "    # Build aligned arrays\n",
        "    rf_classes = list(rf_model.classes_)\n",
        "    aligned_val_rf = np.zeros((len(pred_val_rf_probs), n_classes))\n",
        "    aligned_test_rf = np.zeros((n_test, n_classes))\n",
        "    for idx, cls in enumerate(rf_classes):\n",
        "        aligned_val_rf[:, int(cls)] = pred_val_rf_probs[:, idx]\n",
        "        aligned_test_rf[:, int(cls)] = pred_test_rf_probs[:, idx]\n",
        "    oof_probs_rf[val_idx] = aligned_val_rf\n",
        "    preds_test_rf += aligned_test_rf / N_SPLITS\n",
        "\n",
        "# 20) OOF accuracy per model and ensemble\n",
        "oof_pred_lgb = np.argmax(oof_probs_lgb, axis=1)\n",
        "oof_pred_rf = np.argmax(oof_probs_rf, axis=1)\n",
        "# Ensemble: average probabilities\n",
        "oof_probs_ensemble = (oof_probs_lgb + oof_probs_rf) / 2\n",
        "oof_pred_ensemble = np.argmax(oof_probs_ensemble, axis=1)\n",
        "\n",
        "print(\"\\nOOF Accuracy LGB:\", accuracy_score(y, oof_pred_lgb))\n",
        "print(\"OOF Accuracy RF: \", accuracy_score(y, oof_pred_rf))\n",
        "print(\"OOF Accuracy Ensemble (avg):\", accuracy_score(y, oof_pred_ensemble))\n",
        "\n",
        "# 21) Predicciones finales en test: promedio LGB + RF probabilities\n",
        "final_test_probs = (preds_test_lgb + preds_test_rf) / 2\n",
        "final_test_labels = np.argmax(final_test_probs, axis=1)\n",
        "final_test_labels_str = [inverse_mapping[i] for i in final_test_labels]\n",
        "\n",
        "# 22) Crear submission.csv validando columnas y orden\n",
        "submission = pd.DataFrame({\n",
        "    id_col: test[id_col].values,\n",
        "    \"RENDIMIENTO_GLOBAL\": final_test_labels_str\n",
        "})\n",
        "\n",
        "# Ensure same number rows as test\n",
        "if len(submission) != n_test:\n",
        "    raise ValueError(\"El archivo submission no tiene el mismo n√∫mero de filas que test.csv\")\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"\\n‚úî submission.csv creado correctamente. Primeras filas:\")\n",
        "print(submission.head())\n",
        "\n",
        "# 23) Descargar submission\n",
        "files.download(\"submission.csv\")\n",
        "\n",
        "# 24) Guardar modelos y artefactos (opcional)\n",
        "# bst.save_model(\"lgb_final_model.txt\")  # uncomment if you want to save last LGB model\n",
        "# import joblib\n",
        "# joblib.dump(rf_model, \"rf_final_model.pkl\")\n",
        "\n",
        "print(\"\\nFIN. Revisa submission.csv y s√∫belo manualmente a Kaggle (Submit Predictions).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UX9K62epfFd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}